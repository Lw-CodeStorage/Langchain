{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "自訂工具，但不是使用Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://medium.com/@shravankoninti/agent-tools-basic-code-using-langchain-50e13eb07d92"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.tools.render import render_text_description\n",
    "from langchain.tools import tool\n",
    "from langchain_core.output_parsers import StrOutputParser,JsonOutputParser\n",
    "conn = \"mysql+pymysql://root:123@127.0.0.1/sys\"\n",
    "llm = ChatOllama(\n",
    "    base_url=\"http://localhost:11434\",\n",
    "    model=\"llama3.1\",\n",
    "    temperature=0,\n",
    "    # other params...\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[StructuredTool(name='add', description='這是一個工具，將會將輸入相加', args_schema=<class 'langchain_core.utils.pydantic.add'>, func=<function add at 0x00000219BE019D00>),\n",
       " StructuredTool(name='multiple', description='這是一個工具，將會將輸入相乘', args_schema=<class 'langchain_core.utils.pydantic.multiple'>, func=<function multiple at 0x00000219BE018360>)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "@tool\n",
    "def add(a: float, b: float) -> float:\n",
    "    \"\"\"\n",
    "    這是一個工具，將會將輸入相加\n",
    "    \"\"\"\n",
    "    return a + b\n",
    "\n",
    "@tool\n",
    "def multiple (a: float, b: float) -> float:\n",
    "    \"\"\"\n",
    "    這是一個工具，將會將輸入相乘\n",
    "    \"\"\"\n",
    "    return a * b\n",
    "\n",
    "tools = [add,multiple]\n",
    "tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multiple.invoke({'a':3,'b':3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='\\n你是一個AI助理，以下是每個工具的名稱與使用說明.\\n[StructuredTool(name=\\'add\\', description=\\'這是一個工具，將會將輸入相加\\', args_schema=<class \\'langchain_core.utils.pydantic.add\\'>, func=<function add at 0x00000219BE019D00>), StructuredTool(name=\\'multiple\\', description=\\'這是一個工具，將會將輸入相乘\\', args_schema=<class \\'langchain_core.utils.pydantic.multiple\\'>, func=<function multiple at 0x00000219BE018360>)].\\n根據用戶輸入，返回要使用的工具名稱和輸入.\\n嚴格將返回格式作為帶有\"name\"和\"arguments\"的 JSON格式返回 ```json```，不需要帶有其他額外資訊.                                         \\n'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 注意這裡使用f\"\"將工具加入\n",
    "system_prompt = (f\"\"\"\n",
    "你是一個AI助理，以下是每個工具的名稱與使用說明.\n",
    "{tools}.\n",
    "根據用戶輸入，返回要使用的工具名稱和輸入.\n",
    "嚴格將返回格式作為帶有\"name\"和\"arguments\"的 JSON格式返回 ```json```，不需要帶有其他額外資訊.                                         \n",
    "\"\"\")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\",system_prompt),\n",
    "        (\"user\",\"{input}\")]\n",
    "    )\n",
    "prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "單工具使用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.0"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool_chain_test = prompt| llm |JsonOutputParser()| itemgetter('arguments') | multiple\n",
    "tool_chain_test.invoke({\"input\":\"告訴我3*3是多少\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'好的，我可以幫助你！根據你的問題，我會給出以下答案：\\n\\n\"3*3等於9。\"'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans_prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "根據下列問題和json格式回應，編寫一個針對此問題自然語言的回答\n",
    "問題: {question}\n",
    "回應: {response}                                              \n",
    "\"\"\")\n",
    "\n",
    "#0\n",
    "tool_chain = {\"input\":RunnablePassthrough()}|prompt| llm |JsonOutputParser()| itemgetter('arguments') | multiple\n",
    "chain = {\"question\":itemgetter(\"question\"),\"response\":tool_chain} | ans_prompt | llm | StrOutputParser()\n",
    "chain.invoke({\"question\":\"告訴我3*3是多少\"})\n",
    "\n",
    "#1\n",
    "tool_chain = {\"input\":itemgetter(\"question\")}|prompt| llm |JsonOutputParser()| itemgetter('arguments') | multiple\n",
    "chain = {\"question\":itemgetter(\"question\"),\"response\":tool_chain} | ans_prompt | llm | StrOutputParser()\n",
    "chain.invoke({\"question\":\"告訴我3*3是多少\"})\n",
    "\n",
    "#2\n",
    "tool_chain = {\"input\":RunnablePassthrough()}|prompt| llm |JsonOutputParser()| itemgetter('arguments') | multiple\n",
    "chain = {\"question\":RunnablePassthrough(),\"response\":tool_chain} | ans_prompt | llm | StrOutputParser()\n",
    "chain.invoke(\"告訴我3*3是多少\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openai_env",
   "language": "python",
   "name": "openai_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
