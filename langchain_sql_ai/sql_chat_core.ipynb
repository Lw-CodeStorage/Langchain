{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "conn = \"mysql+pymysql://root:123@127.0.0.1/sys\"\n",
    "llm = ChatOllama(\n",
    "    base_url=\"http://localhost:11434\",\n",
    "    model=\"llama3.1\",\n",
    "    temperature=0,\n",
    "    # other params...\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mysql\n",
      "['employee']\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.utilities import SQLDatabase\n",
    "db = SQLDatabase.from_uri(\n",
    "    \"mysql+pymysql://root:123@127.0.0.1/chinook\", \n",
    "    include_tables=[\"employee\"],\n",
    "    sample_rows_in_table_info=3\n",
    "    )\n",
    "print(db.dialect)\n",
    "print(db.get_usable_table_names())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SELECT COUNT(*) FROM employee'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough,RunnableLambda\n",
    "template = \"\"\"\n",
    "Please generate only an executable SQL query, \n",
    "strictly following the structure and using the schema below.\n",
    " Do not include explanations or additional text.\n",
    "{schema}\n",
    "\n",
    "Question: {question}\n",
    "SQL Query:\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "def get_schema(_):\n",
    "    schema = db.get_table_info()\n",
    "    return schema\n",
    "\n",
    "sql_chain = (\n",
    "    RunnablePassthrough.assign(schema=get_schema)\n",
    "    | prompt\n",
    "    | llm\n",
    "    # | llm.bind(stop=[\"\\nSQLResult:\"])\n",
    "    | StrOutputParser()\n",
    ")\n",
    "sql_chain_test = (\n",
    "    {\n",
    "        \"schema\":RunnableLambda(get_schema),\n",
    "        \"question\": RunnablePassthrough()\n",
    "    }\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser())\n",
    "sql_chain_test.invoke({\"question\": \"總共有多少資料\",\"ttt\":123})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='有 8 個員工的資料。', additional_kwargs={}, response_metadata={'model': 'llama3.1', 'created_at': '2024-10-10T17:57:53.978885703Z', 'message': {'role': 'assistant', 'content': ''}, 'done_reason': 'stop', 'done': True, 'total_duration': 50911984732, 'load_duration': 1821728523, 'prompt_eval_count': 768, 'prompt_eval_duration': 32422428000, 'eval_count': 10, 'eval_duration': 16616797000}, id='run-6aa0ccd1-4ca3-4bba-b1df-dfb941c9c771-0', usage_metadata={'input_tokens': 768, 'output_tokens': 10, 'total_tokens': 778})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "template = \"\"\"Based on the table schema below, question, sql query, and sql response, write a natural language response:\n",
    "{schema}\n",
    "\n",
    "Question: {question}\n",
    "SQL Query: {query}\n",
    "SQL Response: {response}\n",
    "\"\"\"\n",
    "\n",
    "# template = \"\"\"\n",
    "# \"Based on the query results, and aiming to compile all available data as much as possible, \n",
    "# respond in one of the preferred formats: Highcharts.js or a bullet-point summary of the results. \n",
    "# If the data involves trends, statistics, or analysis that can be visually represented, \n",
    "# prioritize determining whether a Highcharts.js visualization can be created, \n",
    "# and only return the Highcharts.chart code. Any other information is unnecessary,\n",
    "# and no explanation is needed for cases where a chart cannot be generated.\":\n",
    "# {schema}\n",
    "\n",
    "# Question: {question}\n",
    "# SQL Query: {query}\n",
    "# SQL Response: {response}\n",
    "# \"\"\"\n",
    "prompt_response = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "def run_query(query):\n",
    "    return db.run(query)\n",
    "\n",
    "main_chain = (\n",
    "    RunnablePassthrough\n",
    "    .assign(query=sql_chain)\n",
    "    .assign(\n",
    "        schema=get_schema,\n",
    "        response=lambda x : run_query(x[\"query\"])\n",
    "    )\n",
    "    | prompt_response\n",
    "    | llm\n",
    ")\n",
    "main_chain.invoke({\"question\":\"有多少資料\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Expected a Runnable, callable or dict.Instead got an unsupported type: <class 'str'>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 17\u001b[0m\n\u001b[0;32m      5\u001b[0m test_prompt \u001b[38;5;241m=\u001b[39m  ChatPromptTemplate\u001b[38;5;241m.\u001b[39mfrom_template(\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;124m    請將\u001b[39m\u001b[38;5;132;01m{content}\u001b[39;00m\u001b[38;5;124m文字，翻成\u001b[39m\u001b[38;5;132;01m{lang}\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m#chain = (test_prompt|llm|StrOutputParser())\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# RunnablePassthrough 用於將上一個輸出傳遞到下一個模型\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m#     \"lang\":\"日文\"\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m#     })\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m chain \u001b[38;5;241m=\u001b[39m (\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhi\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlang\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m日文\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[38;5;241;43m|\u001b[39;49m\u001b[43mtest_prompt\u001b[49m\u001b[38;5;241m|\u001b[39mllm\u001b[38;5;241m|\u001b[39mStrOutputParser())\n",
      "File \u001b[1;32mc:\\Users\\user01\\Desktop\\venv\\openai_env\\Lib\\site-packages\\langchain_core\\runnables\\base.py:586\u001b[0m, in \u001b[0;36mRunnable.__ror__\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    576\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__ror__\u001b[39m(\n\u001b[0;32m    577\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    578\u001b[0m     other: Union[\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    583\u001b[0m     ],\n\u001b[0;32m    584\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m RunnableSerializable[Other, Output]:\n\u001b[0;32m    585\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compose this Runnable with another object to create a RunnableSequence.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 586\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m RunnableSequence(\u001b[43mcoerce_to_runnable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;28mself\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\user01\\Desktop\\venv\\openai_env\\Lib\\site-packages\\langchain_core\\runnables\\base.py:5826\u001b[0m, in \u001b[0;36mcoerce_to_runnable\u001b[1;34m(thing)\u001b[0m\n\u001b[0;32m   5824\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m RunnableLambda(cast(Callable[[Input], Output], thing))\n\u001b[0;32m   5825\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(thing, \u001b[38;5;28mdict\u001b[39m):\n\u001b[1;32m-> 5826\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(Runnable[Input, Output], \u001b[43mRunnableParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mthing\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   5827\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   5828\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m   5829\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected a Runnable, callable or dict.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   5830\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInstead got an unsupported type: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(thing)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   5831\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\user01\\Desktop\\venv\\openai_env\\Lib\\site-packages\\langchain_core\\runnables\\base.py:3537\u001b[0m, in \u001b[0;36mRunnableParallel.__init__\u001b[1;34m(self, steps__, **kwargs)\u001b[0m\n\u001b[0;32m   3534\u001b[0m merged \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39msteps__} \u001b[38;5;28;01mif\u001b[39;00m steps__ \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m {}\n\u001b[0;32m   3535\u001b[0m merged\u001b[38;5;241m.\u001b[39mupdate(kwargs)\n\u001b[0;32m   3536\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m-> 3537\u001b[0m     steps__\u001b[38;5;241m=\u001b[39m{key: \u001b[43mcoerce_to_runnable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mr\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m key, r \u001b[38;5;129;01min\u001b[39;00m merged\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[0;32m   3538\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\user01\\Desktop\\venv\\openai_env\\Lib\\site-packages\\langchain_core\\runnables\\base.py:5828\u001b[0m, in \u001b[0;36mcoerce_to_runnable\u001b[1;34m(thing)\u001b[0m\n\u001b[0;32m   5826\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(Runnable[Input, Output], RunnableParallel(thing))\n\u001b[0;32m   5827\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 5828\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m   5829\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected a Runnable, callable or dict.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   5830\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInstead got an unsupported type: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(thing)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   5831\u001b[0m     )\n",
      "\u001b[1;31mTypeError\u001b[0m: Expected a Runnable, callable or dict.Instead got an unsupported type: <class 'str'>"
     ]
    }
   ],
   "source": [
    "\n",
    "from operator import itemgetter\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough,RunnableLambda\n",
    "test_prompt =  ChatPromptTemplate.from_template(\"\"\"\n",
    "    請將{content}文字，翻成{lang}\n",
    "\"\"\")\n",
    "#chain = (test_prompt|llm|StrOutputParser())\n",
    "\n",
    "# RunnablePassthrough 用於將上一個輸出傳遞到下一個模型，一個字串的時候可單獨使用\n",
    "# 傳入對向若為多個的時候使用 itemgetter(\"question\")\n",
    "# chain = ({\"content\":RunnablePassthrough(),\"lang\":RunnablePassthrough()}|test_prompt|llm|StrOutputParser()) \n",
    "# chain = ({\"content\":itemgetter(\"content\"),\"lang\":itemgetter(\"lang\")}|test_prompt|llm|StrOutputParser())\n",
    "# chain.invoke({\n",
    "#     \"content\":\"hi\",\n",
    "#     \"lang\":\"日文\"\n",
    "#     })\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openai_env",
   "language": "python",
   "name": "openai_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
