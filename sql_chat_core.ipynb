{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "conn = \"mysql+pymysql://root:123@127.0.0.1/sys\"\n",
    "llm = ChatOllama(\n",
    "    base_url=\"http://localhost:11434\",\n",
    "    model=\"llama3.1\",\n",
    "    temperature=0,\n",
    "    # other params...\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mysql\n",
      "['employee']\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.utilities import SQLDatabase\n",
    "db = SQLDatabase.from_uri(\n",
    "    \"mysql+pymysql://root:123@127.0.0.1/chinook\", \n",
    "    include_tables=[\"employee\"],\n",
    "    sample_rows_in_table_info=3\n",
    "    )\n",
    "print(db.dialect)\n",
    "print(db.get_usable_table_names())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "template = \"\"\"\n",
    "Please generate only an executable SQL query, strictly following the structure and using the schema below. Do not include explanations or additional text.\n",
    "{schema}\n",
    "\n",
    "Question: {question}\n",
    "SQL Query:\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "def get_schema(_):\n",
    "    schema = db.get_table_info()\n",
    "    return schema\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SELECT COUNT(*) FROM employee;'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "sql_chain = (\n",
    "    RunnablePassthrough.assign(schema=get_schema)\n",
    "    | prompt\n",
    "    | llm\n",
    "    # | llm.bind(stop=[\"\\nSQLResult:\"])\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# sql_chain.invoke({\"question\": \"總共有多少資料\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Based on the query results, I will provide a bullet-point summary of the results in one of the preferred formats.\\n\\n**Summary:**\\n\\n* Total number of employees: 3 (not 8, as shown in the SQL response. The correct count is 3, based on the provided data.)\\n\\nSince there are only 3 rows of data and no trends or statistics that can be visually represented, I will not provide a Highcharts.js visualization.\\n\\nHere is the summary:\\n\\n* Total number of employees: 3', additional_kwargs={}, response_metadata={'model': 'llama3.1', 'created_at': '2024-09-23T18:20:17.40157916Z', 'message': {'role': 'assistant', 'content': ''}, 'done_reason': 'stop', 'done': True, 'total_duration': 39766226256, 'load_duration': 13454131, 'prompt_eval_count': 847, 'prompt_eval_duration': 27000851000, 'eval_count': 104, 'eval_duration': 12699200000}, id='run-ff22ebef-0e06-4d86-8707-0d2c21fe7169-0', usage_metadata={'input_tokens': 847, 'output_tokens': 104, 'total_tokens': 951})"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "template = \"\"\"Based on the table schema below, question, sql query, and sql response, write a natural language response:\n",
    "{schema}\n",
    "\n",
    "Question: {question}\n",
    "SQL Query: {query}\n",
    "SQL Response: {response}\n",
    "\"\"\"\n",
    "\n",
    "# template = \"\"\"\n",
    "# \"Based on the query results, and aiming to compile all available data as much as possible, \n",
    "# respond in one of the preferred formats: Highcharts.js or a bullet-point summary of the results. \n",
    "# If the data involves trends, statistics, or analysis that can be visually represented, \n",
    "# prioritize determining whether a Highcharts.js visualization can be created, \n",
    "# and only return the Highcharts.chart code. Any other information is unnecessary,\n",
    "# and no explanation is needed for cases where a chart cannot be generated.\":\n",
    "# {schema}\n",
    "\n",
    "# Question: {question}\n",
    "# SQL Query: {query}\n",
    "# SQL Response: {response}\n",
    "# \"\"\"\n",
    "prompt_response = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "def run_query(query):\n",
    "    return db.run(query)\n",
    "\n",
    "main_chain = (\n",
    "    RunnablePassthrough\n",
    "    .assign(query=sql_chain)\n",
    "    .assign(\n",
    "        schema=get_schema,\n",
    "        response=lambda x : run_query(x[\"query\"])\n",
    "    )\n",
    "    | prompt_response\n",
    "    | llm\n",
    ")\n",
    "main_chain.invoke({\"question\":\"有多少資料\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import create_sql_query_chain\n",
    "\n",
    "chain = create_sql_query_chain(llm, db)\n",
    "#chain.get_prompts()[0].pretty_print()\n",
    "response = chain.invoke({\"question\": \"How many employees are there\"})\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools.sql_database.tool import QuerySQLDataBaseTool\n",
    "\n",
    "execute_query = QuerySQLDataBaseTool(db=db)\n",
    "write_query = create_sql_query_chain(llm, db)\n",
    "chain = write_query | execute_query\n",
    "chain.invoke({\"question\": \"How many employees are there\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openai_env",
   "language": "python",
   "name": "openai_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
