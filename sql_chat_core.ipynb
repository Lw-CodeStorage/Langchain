{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "conn = \"mysql+pymysql://root:123@127.0.0.1/sys\"\n",
    "llm = ChatOllama(\n",
    "    base_url=\"http://localhost:11434\",\n",
    "    model=\"llama3.1\",\n",
    "    temperature=0,\n",
    "    # other params...\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mysql\n",
      "['employee']\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.utilities import SQLDatabase\n",
    "db = SQLDatabase.from_uri(\n",
    "    \"mysql+pymysql://root:123@127.0.0.1/chinook\", \n",
    "    include_tables=[\"employee\"],\n",
    "    # sample_rows_in_table_info=2\n",
    "    )\n",
    "print(db.dialect)\n",
    "print(db.get_usable_table_names())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "template = \"\"\"\n",
    "Please generate only an executable SQL query, strictly following the structure and using the schema below. Do not include explanations or additional text.\n",
    "{schema}\n",
    "\n",
    "Question: {question}\n",
    "SQL Query:\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "def get_schema(_):\n",
    "    schema = db.get_table_info()\n",
    "    return schema\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SELECT COUNT(*) FROM employee;'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "sql_chain = (\n",
    "    RunnablePassthrough.assign(schema=get_schema)\n",
    "    | prompt\n",
    "    | llm\n",
    "    # | llm.bind(stop=[\"\\nSQLResult:\"])\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "sql_chain.invoke({\"question\": \"總共有多少資料\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='有 8 個員工的資料。', additional_kwargs={}, response_metadata={'model': 'llama3.1', 'created_at': '2024-09-23T18:01:59.328822752Z', 'message': {'role': 'assistant', 'content': ''}, 'done_reason': 'stop', 'done': True, 'total_duration': 26585888869, 'load_duration': 60422884, 'prompt_eval_count': 767, 'prompt_eval_duration': 25358347000, 'eval_count': 10, 'eval_duration': 1165976000}, id='run-605a9487-db77-4db8-8b3b-8c7e2225eabe-0', usage_metadata={'input_tokens': 767, 'output_tokens': 10, 'total_tokens': 777})"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "template = \"\"\"Based on the table schema below, question, sql query, and sql response, write a natural language response:\n",
    "{schema}\n",
    "\n",
    "Question: {question}\n",
    "SQL Query: {query}\n",
    "SQL Response: {response}\n",
    "\"\"\"\n",
    "prompt_response = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "def run_query(query):\n",
    "    return db.run(query)\n",
    "\n",
    "full_chain = (\n",
    "    RunnablePassthrough\n",
    "    .assign(query=sql_chain)\n",
    "    .assign(\n",
    "        schema=get_schema,\n",
    "        response=lambda x : run_query(x[\"query\"])\n",
    "    )\n",
    "    | prompt_response\n",
    "    | llm\n",
    ")\n",
    "full_chain.invoke({\"question\":\"有多少資料\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import create_sql_query_chain\n",
    "\n",
    "chain = create_sql_query_chain(llm, db)\n",
    "#chain.get_prompts()[0].pretty_print()\n",
    "response = chain.invoke({\"question\": \"How many employees are there\"})\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools.sql_database.tool import QuerySQLDataBaseTool\n",
    "\n",
    "execute_query = QuerySQLDataBaseTool(db=db)\n",
    "write_query = create_sql_query_chain(llm, db)\n",
    "chain = write_query | execute_query\n",
    "chain.invoke({\"question\": \"How many employees are there\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openai_env",
   "language": "python",
   "name": "openai_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
